# handlers/reports/manager_reports.py

import os
from datetime import date

import torch
import matplotlib.pyplot as plt
from aiogram import types, Dispatcher
from sqlalchemy import select
from handlers.reports.ai_model import tokenizer, model

from database.db import async_session_maker
from database.models import User, Task, TaskStatus




# ============================================================
# üîπ –§–£–ù–ö–¶–ò–Ø –ò–ò-–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ô (–ë–ï–ó pipeline)
# ============================================================

def generate_ai_recommendations(stats: dict) -> str:
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞.
    –û—Ç–≤–µ—Ç ‚Äî –ª–∞–∫–æ–Ω–∏—á–Ω—ã–π —Ç–µ–∫—Å—Ç, 3‚Äì4 –∑–∞–∫–æ–Ω—á–µ–Ω–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –≤ –≤–∏–¥–µ –æ–±—ã—á–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.
    """

    prompt = f"""
    –¢—ã ‚Äî –±–∏–∑–Ω–µ—Å-–∞–Ω–∞–ª–∏—Ç–∏–∫ CRM-—Å–∏—Å—Ç–µ–º—ã. –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –¥–∞–Ω–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã –º–µ–Ω–µ–¥–∂–µ—Ä–∞, 
    –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –∫–æ–º–ø–∞–Ω–∏–∏, –∏—Å—Ç–æ—Ä–∏–∏ –∏–ª–∏ –æ–±—â–∏–µ —Ñ—Ä–∞–∑—ã. –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π 3‚Äì4 –¥–µ–ª–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, 
    –∫–æ—Ç–æ—Ä—ã–µ —Ä–µ–∞–ª—å–Ω–æ –ø–æ–º–æ–≥—É—Ç –ø–æ–≤—ã—Å–∏—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∫–æ–º–∞–Ω–¥—ã. –í—ã–¥–∞–≤–∞–π —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –≤ –≤–∏–¥–µ —Å–≤—è–∑–Ω–æ–≥–æ –∞–±–∑–∞—Ü–∞, –±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤, —Å–ø–∏—Å–∫–æ–≤, –æ—Ü–µ–Ω–æ–∫ –∏ –ª—é–±—ã—Ö –º–µ—Ç–æ–∫.

    –ü—Ä–∏–º–µ—Ä –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞:
    –ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–π –ø—Ä–æ—Å—Ä–æ—á–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏ –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–π –∏—Ö –º–µ–∂–¥—É —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞–º–∏. –ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∑–∞–¥–∞—á–∏ –≤ —Ä–∞–±–æ—Ç–µ –∏ –ø–æ–º–æ–≥–∞–π —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞–º —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–º–∏ –∑–∞–¥–∞—á–∞–º–∏. –†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–π –Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø–µ—Ä–µ–≥—Ä—É–∑–∫–∏. –ü–æ–æ—â—Ä—è–π —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –∑–∞ —Å–≤–æ–µ–≤—Ä–µ–º–µ–Ω–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á.

    –î–∞–Ω–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:
    –í—ã–ø–æ–ª–Ω–µ–Ω–æ: {stats['done']}, –í —Ä–∞–±–æ—Ç–µ: {stats['in_progress']}, –ù–æ–≤—ã–µ: {stats['new']}, –ü—Ä–æ—Å—Ä–æ—á–µ–Ω–Ω—ã–µ: {stats['overdue']}, –í—Å–µ–≥–æ –∑–∞–¥–∞—á: {stats['total']}
    """

    try:
        inputs = tokenizer(
            prompt,
            return_tensors="pt",
            truncation=True,
            max_length=512
        )

        with torch.no_grad():
            output = model.generate(
                **inputs,
                max_new_tokens=200,  # —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–ª—è –ø–æ–ª–Ω–æ—Ç—ã –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
                do_sample=True,
                temperature=0.3,
                top_p=0.85,
                repetition_penalty=1.1,
                pad_token_id=tokenizer.eos_token_id
            )

        text = tokenizer.decode(output[0], skip_special_tokens=True)
        # —É–±–∏—Ä–∞–µ–º –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ –ø—Ä–æ–º—Ç–∞
        text = text.replace(prompt, "").strip()

        # –¥–µ–ª–∏–º –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏ –æ–±—Ä–µ–∑–∞–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –æ–±—Ä—ã–≤–∫–∏
        sentences = [s.strip() for s in text.split(".") if len(s.strip()) > 15]
        text = ". ".join(sentences[:4])
        if text and not text.endswith("."):
            text += "."

        # –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –ø—É—Å—Ç–æ–π, –≤–µ—Ä–Ω—É—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π
        if not text:
            return (
                "–†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–π –∑–∞–¥–∞—á–∏ –º–µ–∂–¥—É —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞–º–∏, –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–π —Å—Ä–æ–∫–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π —Å—Ç–∞–±–∏–ª—å–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É –∫–æ–º–∞–Ω–¥—ã."
            )

        return text.strip()

    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ò–ò-–∞–Ω–∞–ª–∏—Ç–∏–∫–∏: {e}")
        return (
            "–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É—Å–∏–ª–∏—Ç—å –∫–æ–Ω—Ç—Ä–æ–ª—å —Å—Ä–æ–∫–æ–≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á –∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–≥—Ä—É–∑–∫–∏ –º–µ–∂–¥—É —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞–º–∏."
        )



# ============================================================
# üîπ –•–ï–ù–î–õ–ï–† –û–¢–ß–Å–¢–ê –ü–û –ó–ê–î–ê–ß–ê–ú (–î–õ–Ø –ú–ï–ù–ï–î–ñ–ï–†–ê)
# ============================================================

async def report_manager_tasks_cb_handler(query: types.CallbackQuery):
    print(f"üìå Callback report_manager_tasks_cb_handler –≤—ã–∑–≤–∞–Ω –¥–ª—è Telegram ID: {query.from_user.id}")
    await query.answer("‚è≥ –§–æ—Ä–º–∏—Ä—É—é –æ—Ç—á—ë—Ç...")

    async with async_session_maker() as session:
        result = await session.execute(
            select(User).where(User.telegram_id == str(query.from_user.id))
        )
        manager = result.scalar_one_or_none()

        if not manager:
            await query.message.answer("‚ùå –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω.")
            return

        result_tasks = await session.execute(select(Task))
        tasks = result_tasks.scalars().all()

        data = {}

        for task in tasks:
            if not task.id_employee:
                continue

            result_emp = await session.execute(
                select(User).where(User.id_user == task.id_employee)
            )
            employee = result_emp.scalar_one_or_none()
            if not employee:
                continue

            if employee.manager_id != manager.id_user:
                continue

            if employee.full_name not in data:
                data[employee.full_name] = {
                    TaskStatus.new: 0,
                    TaskStatus.in_progress: 0,
                    TaskStatus.done: 0,
                    TaskStatus.overdue: 0,
                }

            data[employee.full_name][TaskStatus(task.status)] += 1

        if not data:
            await query.message.answer("‚ÑπÔ∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç—á—ë—Ç–∞.")
            return


        # ====================================================
        # üîπ –°–¢–ê–¢–ò–°–¢–ò–ö–ê
        # ====================================================

        employees_count = len(data)
        total_tasks = sum(sum(v.values()) for v in data.values())

        avg_done = round(sum(v[TaskStatus.done] for v in data.values()) / employees_count, 2)
        avg_in_progress = round(sum(v[TaskStatus.in_progress] for v in data.values()) / employees_count, 2)
        avg_new = round(sum(v[TaskStatus.new] for v in data.values()) / employees_count, 2)
        avg_overdue = round(sum(v[TaskStatus.overdue] for v in data.values()) / employees_count, 2)

        stats = {
            "done": avg_done,
            "in_progress": avg_in_progress,
            "new": avg_new,
            "overdue": avg_overdue,
            "total": total_tasks
        }


        # ====================================================
        # üîπ –î–ò–ê–ì–†–ê–ú–ú–ê
        # ====================================================

        employees = list(data.keys())
        statuses = [
            TaskStatus.done,
            TaskStatus.in_progress,
            TaskStatus.new,
            TaskStatus.overdue
        ]

        colors = {
            TaskStatus.done: "#2E7D32",
            TaskStatus.in_progress: "#1565C0",
            TaskStatus.new: "#F9A825",
            TaskStatus.overdue: "#C62828",
        }

        fig, ax = plt.subplots(figsize=(11, 6))
        bottoms = [0] * len(employees)

        for status in statuses:
            counts = [data[e][status] for e in employees]
            ax.barh(
                employees,
                counts,
                left=bottoms,
                color=colors[status],
                label=status.name.replace("_", " ").title(),
            )
            bottoms = [bottoms[i] + counts[i] for i in range(len(employees))]

        ax.set_xlabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á")
        ax.set_title(
            f"–ù–∞–≥—Ä—É–∑–∫–∞ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ ({date.today()})",
            fontweight="bold"
        )
        ax.invert_yaxis()
        ax.legend()
        plt.tight_layout()

        os.makedirs("reports/images", exist_ok=True)
        filename = "reports/images/manager_tasks_report.png"
        plt.savefig(filename, dpi=150)
        plt.close()


        # ====================================================
        # üîπ –ò–ò-–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò
        # ====================================================

        #ai_text = generate_ai_recommendations(stats)

        caption = (
            "üìä –ù–∞–≥—Ä—É–∑–∫–∞ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤\n\n"
            f"–°—Ä–µ–¥–Ω—è—è –∑–∞–≥—Ä—É–∑–∫–∞ –∫–æ–º–∞–Ω–¥—ã:\n"
            f"‚Ä¢ –í—ã–ø–æ–ª–Ω–µ–Ω–æ: {avg_done}\n"
            f"‚Ä¢ –í —Ä–∞–±–æ—Ç–µ: {avg_in_progress}\n"
            f"‚Ä¢ –ù–æ–≤—ã–µ: {avg_new}\n"
            f"‚Ä¢ –ü—Ä–æ—Å—Ä–æ—á–µ–Ω–Ω—ã–µ: {avg_overdue}\n\n"
            #f"ü§ñ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ò–ò:\n{ai_text}"
        )

        await query.message.answer_photo(
            types.InputFile(filename),
            caption=caption
        )

        print(f"üéØ –û—Ç—á—ë—Ç —Å –ò–ò-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω: {manager.full_name}")


# ============================================================
# üîπ –†–ï–ì–ò–°–¢–†–ê–¶–ò–Ø –•–ï–ù–î–õ–ï–†–ê
# ============================================================

def register_manager_reports(dp: Dispatcher):
    dp.register_callback_query_handler(
        report_manager_tasks_cb_handler,
        lambda c: c.data == "report_manager_tasks",
    )

    print("‚úÖ –•–µ–Ω–¥–ª–µ—Ä report_manager_tasks_cb_handler –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω")
